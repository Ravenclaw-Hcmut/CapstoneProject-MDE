{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000006_luan_disp.jpeg\n",
      "   - assets\\0000000006_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000007_luan_disp.jpeg\n",
      "   - assets\\0000000007_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000030_luan_disp.jpeg\n",
      "   - assets\\0000000030_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000031_luan_disp.jpeg\n",
      "   - assets\\0000000031_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000044_luan_disp.jpeg\n",
      "   - assets\\0000000044_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000049_luan_disp.jpeg\n",
      "   - assets\\0000000049_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000068_luan_disp.jpeg\n",
      "   - assets\\0000000068_luan_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\luan\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000095_luan_disp.jpeg\n",
      "   - assets\\0000000095_luan_disp.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000006.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000007.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000030.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000031.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000044.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000049.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000068.png --model_name luan\n",
    "!python test_simple.py --image_path assets/0000000095.png --model_name luan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000006_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000006_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000007_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000007_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000030_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000030_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000031_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000031_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000044_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000044_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000049_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000049_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000068_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000068_mono_640x192_disp.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000095_mono_640x192_disp.jpeg\n",
      "   - assets\\0000000095_mono_640x192_disp.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000006.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000007.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000030.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000031.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000044.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000049.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000068.png --model_name mono_640x192 --ext png\n",
    "!python test_simple.py --image_path assets/0000000095.png --model_name mono_640x192 --ext png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0000000006.png\n",
    "0000000007.png\n",
    "0000000030.png\n",
    "0000000031.png\n",
    "0000000044.png\n",
    "0000000049.png\n",
    "0000000068.png\n",
    "0000000095.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Forth year\\\\CAPSTONE PROJECT\\\\222\\\\CapstoneProject-MDE\\\\monodepth2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %cd ../../\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000006_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000006_depth.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000006.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000007.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000030.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000031.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000044.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000049.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000068.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "# !python test_simple.py --image_path assets/0000000095.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000007_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000007_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000030_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000030_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000031_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000031_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000044_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000044_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000049_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000049_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000068_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000068_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\mono+stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000095_mono+stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000095_mono+stereo_640x192_depth.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000007.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000030.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000031.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000044.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000049.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000068.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000095.png --model_name mono+stereo_640x192 --ext png  --pred_metric_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000006_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000006_stereo_640x192_depth.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000006.png --model_name stereo_640x192 --ext png  --pred_metric_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "-> Downloading pretrained model to models\\stereo_640x192.zip\n",
      "   Unzipping model...\n",
      "   Model unzipped to models\\stereo_640x192\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000007_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000007_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000030_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000030_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000031_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000031_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000044_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000044_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000049_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000049_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000068_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000068_stereo_640x192_depth.npy\n",
      "-> Done!\n",
      "cuda\n",
      "-> Loading model from  models\\stereo_640x192\n",
      "   Loading pretrained encoder\n",
      "   Loading pretrained decoder\n",
      "-> Predicting on 1 test images\n",
      "   Processed 1 of 1 images - saved predictions to:\n",
      "   - assets\\0000000095_stereo_640x192_disp.jpeg\n",
      "   - assets\\0000000095_stereo_640x192_depth.npy\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "!python test_simple.py --image_path assets/0000000007.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000030.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000031.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000044.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000049.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000068.png --model_name stereo_640x192 --ext png  --pred_metric_depth\n",
    "!python test_simple.py --image_path assets/0000000095.png --model_name stereo_640x192 --ext png  --pred_metric_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Forth year\\CAPSTONE PROJECT\\222\n"
     ]
    }
   ],
   "source": [
    "%cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_camera_plane' from 'layers' (e:\\Forth year\\CAPSTONE PROJECT\\222\\CapstoneProject-MDE\\monodepth2\\layers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32me:\\Forth year\\CAPSTONE PROJECT\\222\\CapstoneProject-MDE\\monodepth2\\infer.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Forth%20year/CAPSTONE%20PROJECT/222/CapstoneProject-MDE/monodepth2/infer.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPlaneDepth\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfal_net\u001b[39;00m \u001b[39mimport\u001b[39;00m BackBone\n",
      "File \u001b[1;32me:\\Forth year\\CAPSTONE PROJECT\\222\\PlaneDepth\\networks\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m ResnetEncoder\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdepth_decoder\u001b[39;00m \u001b[39mimport\u001b[39;00m DepthDecoder, DepthDecoderContinuous\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mplade_net\u001b[39;00m \u001b[39mimport\u001b[39;00m PladeNet\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfal_net\u001b[39;00m \u001b[39mimport\u001b[39;00m FalNet\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpose_net\u001b[39;00m \u001b[39mimport\u001b[39;00m ResnetPoseEncoder, PoseDecoder, PladePoseNet\n",
      "File \u001b[1;32me:\\Forth year\\CAPSTONE PROJECT\\222\\PlaneDepth\\networks\\plade_net.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m create_camera_plane\n\u001b[0;32m     26\u001b[0m \u001b[39m# def FAL_net2B_gep(data=None, no_levels=49):\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m#     model = FAL_net(batchNorm=False, no_levels=no_levels)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m#     if data is not None:\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m#         model.load_state_dict(data['state_dict'])\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m#     return model\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconv_elu\u001b[39m(batchNorm, in_planes, out_planes, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, pad\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'create_camera_plane' from 'layers' (e:\\Forth year\\CAPSTONE PROJECT\\222\\CapstoneProject-MDE\\monodepth2\\layers.py)"
     ]
    }
   ],
   "source": [
    "from PlaneDepth.networks.fal_net import BackBone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./PlaneDepth/models/self-distillation/encoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_depth = torch.load(\"./PlaneDepth/models/self-distillation/depth.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"CapstoneProject-MDE/monodepth2/assets/0000000006.png\"\n",
    "\n",
    "input_image = pil.open(image_path).convert('RGB')\n",
    "original_width, original_height = input_image.size\n",
    "input_image = input_image.resize((420, 192), pil.LANCZOS)\n",
    "input_image = transforms.ToTensor()(input_image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0510, 0.0667, 0.0863,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0667, 0.0941, 0.0784,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0510, 0.0745, 0.0627,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.3804, 0.4863, 0.5490,  ..., 0.7608, 0.8078, 0.8824],\n",
       "          [0.4000, 0.4941, 0.4745,  ..., 0.6392, 0.6471, 0.7098],\n",
       "          [0.4588, 0.5137, 0.5137,  ..., 0.5412, 0.5333, 0.5725]],\n",
       "\n",
       "         [[0.0588, 0.0667, 0.1176,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0588, 0.0784, 0.0980,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0980, 0.0824, 0.0667,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.4118, 0.4510, 0.6000,  ..., 0.7333, 0.7608, 0.8392],\n",
       "          [0.4078, 0.4196, 0.5059,  ..., 0.6235, 0.6275, 0.6588],\n",
       "          [0.5098, 0.4902, 0.5294,  ..., 0.5176, 0.5098, 0.5294]],\n",
       "\n",
       "         [[0.0392, 0.0431, 0.0706,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0471, 0.0431, 0.0627,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          [0.0627, 0.0471, 0.0471,  ..., 1.0000, 1.0000, 1.0000],\n",
       "          ...,\n",
       "          [0.2549, 0.2863, 0.3451,  ..., 0.6980, 0.6980, 0.7490],\n",
       "          [0.2431, 0.2745, 0.3020,  ..., 0.5882, 0.5843, 0.6314],\n",
       "          [0.3490, 0.3098, 0.3098,  ..., 0.5059, 0.5059, 0.5176]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\Forth year\\CAPSTONE PROJECT\\222\\CapstoneProject-MDE\\monodepth2\\infer.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Forth%20year/CAPSTONE%20PROJECT/222/CapstoneProject-MDE/monodepth2/infer.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(input_image)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "model(input_imagea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
